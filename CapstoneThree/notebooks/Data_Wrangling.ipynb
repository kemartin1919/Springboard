{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframe with player_id column and HoF_nomination column (with all values equaling 1) for all players nominated for the Hall of Fame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hof = pd.read_csv('~/Desktop/Springboard/CapstoneThree/data/raw/hall_of_fame.csv')\n",
    "df_hof = df_hof[df_hof['category']=='Player']\n",
    "hof_ids = pd.DataFrame(df_hof['player_id'].unique(), columns=['player_id']).set_index('player_id')\n",
    "hof_ids['HoF_nomination']=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in general player info, batting, and appearances (specifically games played and games started columns) dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_player = pd.read_csv('~/Desktop/Springboard/CapstoneThree/data/raw/player.csv')\n",
    "df_batting = pd.read_csv('~/Desktop/Springboard/CapstoneThree/data/raw/batting.csv')\n",
    "df_appearances = pd.read_csv('~/Desktop/Springboard/CapstoneThree/data/raw/appearances.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create temporary dataframe by merging the batting and appearance datasets and group by player_id mean. We now have one row of data with average stats for each player's career"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.merge(left=df_batting, right=df_appearances[['player_id','g_all','gs']], on='player_id')\n",
    "df_temp = df_temp.groupby(['player_id']).mean().drop(['year', 'stint'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge temporary dataframe with general player info columns of player df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.merge(left=df_temp, right=df_player[['player_id','weight','height','debut','final_game']], on='player_id').set_index('player_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert final and debut games to datetime and create new career length column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['final_game'] = pd.to_datetime(df_temp['final_game'])\n",
    "df_temp['debut'] = pd.to_datetime(df_temp['debut'])\n",
    "\n",
    "df_temp['career_length']=df_temp['final_game'] - df_temp['debut']\n",
    "df_temp['career_length']=df_temp['career_length'].dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Left join temp df with HoF df, creating a new column \"HoF_nomination\" where a 1 indicates the player was nominated and a 0 indicates they were not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.merge(left=df_temp, right=hof_ids, on='player_id', how='left')\n",
    "df_temp['HoF_nomination']=df_temp['HoF_nomination'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in pitching df, filter out years before 1936, group by player_id to get career averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pitching = pd.read_csv('~/Desktop/Springboard/CapstoneThree/data/raw/pitching.csv')\n",
    "df_pitching = df_pitching[df_pitching['year']>=1936]\n",
    "df_pitching = df_pitching.groupby(['player_id']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outer join temp df and pitching df with an Indicator. This way we can filter non-pitchers (right_only) from pitchers (both). Drop all player ineligible for HoF because their career length was less than 10 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    17491\n",
      "1.0     1162\n",
      "Name: HoF_nomination, dtype: int64\n",
      "0.0    2864\n",
      "1.0    1117\n",
      "Name: HoF_nomination, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_merged = pd.merge(left=df_pitching, right=df_temp, how='outer', on='player_id', indicator=True)\n",
    "print(df_merged['HoF_nomination'].value_counts())\n",
    "df_merged = df_merged[df_merged['career_length']>3284]\n",
    "print(df_merged['HoF_nomination'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bin players into decades by average year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins=[1929.9,1939.9,1949.9,1959.9,1969.9,1979.9,1989.9,1999.9,2009.9,2019.9]\n",
    "df_merged['Binned_Decade'] = pd.cut(df_merged['year'], bins)\n",
    "\n",
    "dummy = pd.get_dummies(df_merged['Binned_Decade'])\n",
    "df_merged = pd.concat([df_merged,dummy], axis=1)\n",
    "df_merged.drop(columns=['year', 'Binned_Decade'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create pitchers dataframe my filtering on the merge indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "df_pitchers = df_merged[df_merged['_merge']=='both']\n",
    "df_pitchers.drop('_merge', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns that are irrelevant to pitchers or that had many NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(df_pitchers.columns)\n",
    "drop_column_numbers = [0,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44]\n",
    "drop_columns = [columns[i] for i in drop_column_numbers]\n",
    "df_pitchers.drop(drop_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframe df_ineligible_pitchers that includes all pitchers ineligible for HoF nomination because they are either currently playing or retired less than 5 years ago. Delete all these pitchers from main pitcher dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ineligible_pitchers = df_pitchers[df_pitchers['final_game'] > '2011-01-01']\n",
    "df_pitchers = df_pitchers[df_pitchers['final_game'] <= '2011-01-01']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace NaNs with means, drop debut/final game columns since they are not int/floats and have already been used to filter and create decade bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pitchers.fillna(df_pitchers.mean(), inplace=True)\n",
    "df_pitchers.drop(columns=['debut', 'final_game'], inplace=True)\n",
    "\n",
    "df_ineligible_pitchers.fillna(df_ineligible_pitchers.mean(), inplace=True)\n",
    "df_ineligible_pitchers.drop(columns=['debut', 'final_game'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write out csv of both pitcher dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pitchers.to_csv('~/Desktop/Springboard/CapstoneThree/data/final/pitchers.csv', index=False)\n",
    "df_ineligible_pitchers.to_csv('~/Desktop/Springboard/CapstoneThree/data/final/ineligible_pitchers.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create batters dataframe my filtering on the merge indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "df_batters = df_merged[df_merged['_merge']=='right_only']\n",
    "df_batters.drop('_merge', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns that are irrelevant to batters or that had many NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(df_batters.columns)\n",
    "drop_column_numbers = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,35,38,41,42,44]\n",
    "drop_columns = [columns[i] for i in drop_column_numbers]\n",
    "df_batters.drop(drop_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframe df_ineligible_batters that includes all batters ineligible for HoF nomination because they are either currently playing or retired less than 5 years ago. Delete all these batters from main batter dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ineligible_batters = df_batters[df_batters['final_game'] > '2011-01-01']\n",
    "df_batters = df_batters[df_batters['final_game'] <= '2011-01-01']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace NaNs with means, drop debut/final game columns since they are not int/floats and have already been used to filter and create decade bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_batters.fillna(df_batters.mean(), inplace=True)\n",
    "df_batters.drop(columns=['debut', 'final_game'], inplace=True)\n",
    "\n",
    "df_ineligible_batters.fillna(df_ineligible_batters.mean(), inplace=True)\n",
    "df_ineligible_batters.drop(columns=['debut', 'final_game'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write out csv of both batter dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_batters.to_csv('~/Desktop/Springboard/CapstoneThree/data/final/batters.csv', index=False)\n",
    "df_ineligible_batters.to_csv('~/Desktop/Springboard/CapstoneThree/data/final/ineligible_batters.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
